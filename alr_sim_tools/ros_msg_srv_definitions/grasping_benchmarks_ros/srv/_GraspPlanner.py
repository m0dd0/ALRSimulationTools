# This Python file uses the following encoding: utf-8
"""autogenerated by genpy from grasping_benchmarks_ros/GraspPlannerRequest.msg. Do not edit."""
import codecs
import sys
python3 = True if sys.hexversion > 0x03000000 else False
import genpy
import struct

import geometry_msgs.msg
import sensor_msgs.msg
import std_msgs.msg

class GraspPlannerRequest(genpy.Message):
  _md5sum = "b7597e2dc9c79710f8f16eb74f495f94"
  _type = "grasping_benchmarks_ros/GraspPlannerRequest"
  _has_header = False  # flag to mark the presence of a Header object
  _full_text = """# request params for grasp planners (not all of these must be filled in)

# color and depth images
sensor_msgs/Image color_image
sensor_msgs/Image depth_image
sensor_msgs/Image seg_image # assumed to be binary since no segmentation id is provided

# camera info and intrinsics
sensor_msgs/CameraInfo camera_info

# pointcloud
sensor_msgs/PointCloud2 cloud # in world frame

# camera parameers
geometry_msgs/PoseStamped view_point

# additional parameters
geometry_msgs/Pose aruco_board
bool grasp_filter_flag

# number of candidates to return
int16 n_of_candidates


================================================================================
MSG: sensor_msgs/Image
# This message contains an uncompressed image
# (0, 0) is at top-left corner of image
#

Header header        # Header timestamp should be acquisition time of image
                     # Header frame_id should be optical frame of camera
                     # origin of frame should be optical center of camera
                     # +x should point to the right in the image
                     # +y should point down in the image
                     # +z should point into to plane of the image
                     # If the frame_id here and the frame_id of the CameraInfo
                     # message associated with the image conflict
                     # the behavior is undefined

uint32 height         # image height, that is, number of rows
uint32 width          # image width, that is, number of columns

# The legal values for encoding are in file src/image_encodings.cpp
# If you want to standardize a new string format, join
# ros-users@lists.sourceforge.net and send an email proposing a new encoding.

string encoding       # Encoding of pixels -- channel meaning, ordering, size
                      # taken from the list of strings in include/sensor_msgs/image_encodings.h

uint8 is_bigendian    # is this data bigendian?
uint32 step           # Full row length in bytes
uint8[] data          # actual matrix data, size is (step * rows)

================================================================================
MSG: std_msgs/Header
# Standard metadata for higher-level stamped data types.
# This is generally used to communicate timestamped data 
# in a particular coordinate frame.
# 
# sequence ID: consecutively increasing ID 
uint32 seq
#Two-integer timestamp that is expressed as:
# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')
# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')
# time-handling sugar is provided by the client library
time stamp
#Frame this data is associated with
string frame_id

================================================================================
MSG: sensor_msgs/CameraInfo
# This message defines meta information for a camera. It should be in a
# camera namespace on topic "camera_info" and accompanied by up to five
# image topics named:
#
#   image_raw - raw data from the camera driver, possibly Bayer encoded
#   image            - monochrome, distorted
#   image_color      - color, distorted
#   image_rect       - monochrome, rectified
#   image_rect_color - color, rectified
#
# The image_pipeline contains packages (image_proc, stereo_image_proc)
# for producing the four processed image topics from image_raw and
# camera_info. The meaning of the camera parameters are described in
# detail at http://www.ros.org/wiki/image_pipeline/CameraInfo.
#
# The image_geometry package provides a user-friendly interface to
# common operations using this meta information. If you want to, e.g.,
# project a 3d point into image coordinates, we strongly recommend
# using image_geometry.
#
# If the camera is uncalibrated, the matrices D, K, R, P should be left
# zeroed out. In particular, clients may assume that K[0] == 0.0
# indicates an uncalibrated camera.

#######################################################################
#                     Image acquisition info                          #
#######################################################################

# Time of image acquisition, camera coordinate frame ID
Header header    # Header timestamp should be acquisition time of image
                 # Header frame_id should be optical frame of camera
                 # origin of frame should be optical center of camera
                 # +x should point to the right in the image
                 # +y should point down in the image
                 # +z should point into the plane of the image


#######################################################################
#                      Calibration Parameters                         #
#######################################################################
# These are fixed during camera calibration. Their values will be the #
# same in all messages until the camera is recalibrated. Note that    #
# self-calibrating systems may "recalibrate" frequently.              #
#                                                                     #
# The internal parameters can be used to warp a raw (distorted) image #
# to:                                                                 #
#   1. An undistorted image (requires D and K)                        #
#   2. A rectified image (requires D, K, R)                           #
# The projection matrix P projects 3D points into the rectified image.#
#######################################################################

# The image dimensions with which the camera was calibrated. Normally
# this will be the full camera resolution in pixels.
uint32 height
uint32 width

# The distortion model used. Supported models are listed in
# sensor_msgs/distortion_models.h. For most cameras, "plumb_bob" - a
# simple model of radial and tangential distortion - is sufficient.
string distortion_model

# The distortion parameters, size depending on the distortion model.
# For "plumb_bob", the 5 parameters are: (k1, k2, t1, t2, k3).
float64[] D

# Intrinsic camera matrix for the raw (distorted) images.
#     [fx  0 cx]
# K = [ 0 fy cy]
#     [ 0  0  1]
# Projects 3D points in the camera coordinate frame to 2D pixel
# coordinates using the focal lengths (fx, fy) and principal point
# (cx, cy).
float64[9]  K # 3x3 row-major matrix

# Rectification matrix (stereo cameras only)
# A rotation matrix aligning the camera coordinate system to the ideal
# stereo image plane so that epipolar lines in both stereo images are
# parallel.
float64[9]  R # 3x3 row-major matrix

# Projection/camera matrix
#     [fx'  0  cx' Tx]
# P = [ 0  fy' cy' Ty]
#     [ 0   0   1   0]
# By convention, this matrix specifies the intrinsic (camera) matrix
#  of the processed (rectified) image. That is, the left 3x3 portion
#  is the normal camera intrinsic matrix for the rectified image.
# It projects 3D points in the camera coordinate frame to 2D pixel
#  coordinates using the focal lengths (fx', fy') and principal point
#  (cx', cy') - these may differ from the values in K.
# For monocular cameras, Tx = Ty = 0. Normally, monocular cameras will
#  also have R = the identity and P[1:3,1:3] = K.
# For a stereo pair, the fourth column [Tx Ty 0]' is related to the
#  position of the optical center of the second camera in the first
#  camera's frame. We assume Tz = 0 so both cameras are in the same
#  stereo image plane. The first camera always has Tx = Ty = 0. For
#  the right (second) camera of a horizontal stereo pair, Ty = 0 and
#  Tx = -fx' * B, where B is the baseline between the cameras.
# Given a 3D point [X Y Z]', the projection (x, y) of the point onto
#  the rectified image is given by:
#  [u v w]' = P * [X Y Z 1]'
#         x = u / w
#         y = v / w
#  This holds for both images of a stereo pair.
float64[12] P # 3x4 row-major matrix


#######################################################################
#                      Operational Parameters                         #
#######################################################################
# These define the image region actually captured by the camera       #
# driver. Although they affect the geometry of the output image, they #
# may be changed freely without recalibrating the camera.             #
#######################################################################

# Binning refers here to any camera setting which combines rectangular
#  neighborhoods of pixels into larger "super-pixels." It reduces the
#  resolution of the output image to
#  (width / binning_x) x (height / binning_y).
# The default values binning_x = binning_y = 0 is considered the same
#  as binning_x = binning_y = 1 (no subsampling).
uint32 binning_x
uint32 binning_y

# Region of interest (subwindow of full camera resolution), given in
#  full resolution (unbinned) image coordinates. A particular ROI
#  always denotes the same window of pixels on the camera sensor,
#  regardless of binning settings.
# The default setting of roi (all values 0) is considered the same as
#  full resolution (roi.width = width, roi.height = height).
RegionOfInterest roi

================================================================================
MSG: sensor_msgs/RegionOfInterest
# This message is used to specify a region of interest within an image.
#
# When used to specify the ROI setting of the camera when the image was
# taken, the height and width fields should either match the height and
# width fields for the associated image; or height = width = 0
# indicates that the full resolution image was captured.

uint32 x_offset  # Leftmost pixel of the ROI
                 # (0 if the ROI includes the left edge of the image)
uint32 y_offset  # Topmost pixel of the ROI
                 # (0 if the ROI includes the top edge of the image)
uint32 height    # Height of ROI
uint32 width     # Width of ROI

# True if a distinct rectified ROI should be calculated from the "raw"
# ROI in this message. Typically this should be False if the full image
# is captured (ROI not used), and True if a subwindow is captured (ROI
# used).
bool do_rectify

================================================================================
MSG: sensor_msgs/PointCloud2
# This message holds a collection of N-dimensional points, which may
# contain additional information such as normals, intensity, etc. The
# point data is stored as a binary blob, its layout described by the
# contents of the "fields" array.

# The point cloud data may be organized 2d (image-like) or 1d
# (unordered). Point clouds organized as 2d images may be produced by
# camera depth sensors such as stereo or time-of-flight.

# Time of sensor data acquisition, and the coordinate frame ID (for 3d
# points).
Header header

# 2D structure of the point cloud. If the cloud is unordered, height is
# 1 and width is the length of the point cloud.
uint32 height
uint32 width

# Describes the channels and their layout in the binary data blob.
PointField[] fields

bool    is_bigendian # Is this data bigendian?
uint32  point_step   # Length of a point in bytes
uint32  row_step     # Length of a row in bytes
uint8[] data         # Actual point data, size is (row_step*height)

bool is_dense        # True if there are no invalid points

================================================================================
MSG: sensor_msgs/PointField
# This message holds the description of one point entry in the
# PointCloud2 message format.
uint8 INT8    = 1
uint8 UINT8   = 2
uint8 INT16   = 3
uint8 UINT16  = 4
uint8 INT32   = 5
uint8 UINT32  = 6
uint8 FLOAT32 = 7
uint8 FLOAT64 = 8

string name      # Name of field
uint32 offset    # Offset from start of point struct
uint8  datatype  # Datatype enumeration, see above
uint32 count     # How many elements in the field

================================================================================
MSG: geometry_msgs/PoseStamped
# A Pose with reference coordinate frame and timestamp
Header header
Pose pose

================================================================================
MSG: geometry_msgs/Pose
# A representation of pose in free space, composed of position and orientation. 
Point position
Quaternion orientation

================================================================================
MSG: geometry_msgs/Point
# This contains the position of a point in free space
float64 x
float64 y
float64 z

================================================================================
MSG: geometry_msgs/Quaternion
# This represents an orientation in free space in quaternion form.

float64 x
float64 y
float64 z
float64 w
"""
  __slots__ = ['color_image','depth_image','seg_image','camera_info','cloud','view_point','aruco_board','grasp_filter_flag','n_of_candidates']
  _slot_types = ['sensor_msgs/Image','sensor_msgs/Image','sensor_msgs/Image','sensor_msgs/CameraInfo','sensor_msgs/PointCloud2','geometry_msgs/PoseStamped','geometry_msgs/Pose','bool','int16']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.

    The available fields are:
       color_image,depth_image,seg_image,camera_info,cloud,view_point,aruco_board,grasp_filter_flag,n_of_candidates

    :param args: complete set of field values, in .msg order
    :param kwds: use keyword arguments corresponding to message field names
    to set specific fields.
    """
    if args or kwds:
      super(GraspPlannerRequest, self).__init__(*args, **kwds)
      # message fields cannot be None, assign default values for those that are
      if self.color_image is None:
        self.color_image = sensor_msgs.msg.Image()
      if self.depth_image is None:
        self.depth_image = sensor_msgs.msg.Image()
      if self.seg_image is None:
        self.seg_image = sensor_msgs.msg.Image()
      if self.camera_info is None:
        self.camera_info = sensor_msgs.msg.CameraInfo()
      if self.cloud is None:
        self.cloud = sensor_msgs.msg.PointCloud2()
      if self.view_point is None:
        self.view_point = geometry_msgs.msg.PoseStamped()
      if self.aruco_board is None:
        self.aruco_board = geometry_msgs.msg.Pose()
      if self.grasp_filter_flag is None:
        self.grasp_filter_flag = False
      if self.n_of_candidates is None:
        self.n_of_candidates = 0
    else:
      self.color_image = sensor_msgs.msg.Image()
      self.depth_image = sensor_msgs.msg.Image()
      self.seg_image = sensor_msgs.msg.Image()
      self.camera_info = sensor_msgs.msg.CameraInfo()
      self.cloud = sensor_msgs.msg.PointCloud2()
      self.view_point = geometry_msgs.msg.PoseStamped()
      self.aruco_board = geometry_msgs.msg.Pose()
      self.grasp_filter_flag = False
      self.n_of_candidates = 0

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    :param buff: buffer, ``StringIO``
    """
    try:
      _x = self
      buff.write(_get_struct_3I().pack(_x.color_image.header.seq, _x.color_image.header.stamp.secs, _x.color_image.header.stamp.nsecs))
      _x = self.color_image.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.color_image.height, _x.color_image.width))
      _x = self.color_image.encoding
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_BI().pack(_x.color_image.is_bigendian, _x.color_image.step))
      _x = self.color_image.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_3I().pack(_x.depth_image.header.seq, _x.depth_image.header.stamp.secs, _x.depth_image.header.stamp.nsecs))
      _x = self.depth_image.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.depth_image.height, _x.depth_image.width))
      _x = self.depth_image.encoding
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_BI().pack(_x.depth_image.is_bigendian, _x.depth_image.step))
      _x = self.depth_image.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_3I().pack(_x.seg_image.header.seq, _x.seg_image.header.stamp.secs, _x.seg_image.header.stamp.nsecs))
      _x = self.seg_image.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.seg_image.height, _x.seg_image.width))
      _x = self.seg_image.encoding
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_BI().pack(_x.seg_image.is_bigendian, _x.seg_image.step))
      _x = self.seg_image.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_3I().pack(_x.camera_info.header.seq, _x.camera_info.header.stamp.secs, _x.camera_info.header.stamp.nsecs))
      _x = self.camera_info.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.camera_info.height, _x.camera_info.width))
      _x = self.camera_info.distortion_model
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.camera_info.D)
      buff.write(_struct_I.pack(length))
      pattern = '<%sd'%length
      buff.write(struct.Struct(pattern).pack(*self.camera_info.D))
      buff.write(_get_struct_9d().pack(*self.camera_info.K))
      buff.write(_get_struct_9d().pack(*self.camera_info.R))
      buff.write(_get_struct_12d().pack(*self.camera_info.P))
      _x = self
      buff.write(_get_struct_6IB3I().pack(_x.camera_info.binning_x, _x.camera_info.binning_y, _x.camera_info.roi.x_offset, _x.camera_info.roi.y_offset, _x.camera_info.roi.height, _x.camera_info.roi.width, _x.camera_info.roi.do_rectify, _x.cloud.header.seq, _x.cloud.header.stamp.secs, _x.cloud.header.stamp.nsecs))
      _x = self.cloud.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.cloud.height, _x.cloud.width))
      length = len(self.cloud.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.cloud.fields:
        _x = val1.name
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = val1
        buff.write(_get_struct_IBI().pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_get_struct_B2I().pack(_x.cloud.is_bigendian, _x.cloud.point_step, _x.cloud.row_step))
      _x = self.cloud.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_B3I().pack(_x.cloud.is_dense, _x.view_point.header.seq, _x.view_point.header.stamp.secs, _x.view_point.header.stamp.nsecs))
      _x = self.view_point.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_14dBh().pack(_x.view_point.pose.position.x, _x.view_point.pose.position.y, _x.view_point.pose.position.z, _x.view_point.pose.orientation.x, _x.view_point.pose.orientation.y, _x.view_point.pose.orientation.z, _x.view_point.pose.orientation.w, _x.aruco_board.position.x, _x.aruco_board.position.y, _x.aruco_board.position.z, _x.aruco_board.orientation.x, _x.aruco_board.orientation.y, _x.aruco_board.orientation.z, _x.aruco_board.orientation.w, _x.grasp_filter_flag, _x.n_of_candidates))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    :param str: byte array of serialized message, ``str``
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.color_image is None:
        self.color_image = sensor_msgs.msg.Image()
      if self.depth_image is None:
        self.depth_image = sensor_msgs.msg.Image()
      if self.seg_image is None:
        self.seg_image = sensor_msgs.msg.Image()
      if self.camera_info is None:
        self.camera_info = sensor_msgs.msg.CameraInfo()
      if self.cloud is None:
        self.cloud = sensor_msgs.msg.PointCloud2()
      if self.view_point is None:
        self.view_point = geometry_msgs.msg.PoseStamped()
      if self.aruco_board is None:
        self.aruco_board = geometry_msgs.msg.Pose()
      end = 0
      _x = self
      start = end
      end += 12
      (_x.color_image.header.seq, _x.color_image.header.stamp.secs, _x.color_image.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.color_image.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.color_image.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.color_image.height, _x.color_image.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.color_image.encoding = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.color_image.encoding = str[start:end]
      _x = self
      start = end
      end += 5
      (_x.color_image.is_bigendian, _x.color_image.step,) = _get_struct_BI().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.color_image.data = str[start:end]
      _x = self
      start = end
      end += 12
      (_x.depth_image.header.seq, _x.depth_image.header.stamp.secs, _x.depth_image.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.depth_image.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.depth_image.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.depth_image.height, _x.depth_image.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.depth_image.encoding = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.depth_image.encoding = str[start:end]
      _x = self
      start = end
      end += 5
      (_x.depth_image.is_bigendian, _x.depth_image.step,) = _get_struct_BI().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.depth_image.data = str[start:end]
      _x = self
      start = end
      end += 12
      (_x.seg_image.header.seq, _x.seg_image.header.stamp.secs, _x.seg_image.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.seg_image.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.seg_image.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.seg_image.height, _x.seg_image.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.seg_image.encoding = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.seg_image.encoding = str[start:end]
      _x = self
      start = end
      end += 5
      (_x.seg_image.is_bigendian, _x.seg_image.step,) = _get_struct_BI().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.seg_image.data = str[start:end]
      _x = self
      start = end
      end += 12
      (_x.camera_info.header.seq, _x.camera_info.header.stamp.secs, _x.camera_info.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.camera_info.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.camera_info.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.camera_info.height, _x.camera_info.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.camera_info.distortion_model = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.camera_info.distortion_model = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%sd'%length
      start = end
      s = struct.Struct(pattern)
      end += s.size
      self.camera_info.D = s.unpack(str[start:end])
      start = end
      end += 72
      self.camera_info.K = _get_struct_9d().unpack(str[start:end])
      start = end
      end += 72
      self.camera_info.R = _get_struct_9d().unpack(str[start:end])
      start = end
      end += 96
      self.camera_info.P = _get_struct_12d().unpack(str[start:end])
      _x = self
      start = end
      end += 37
      (_x.camera_info.binning_x, _x.camera_info.binning_y, _x.camera_info.roi.x_offset, _x.camera_info.roi.y_offset, _x.camera_info.roi.height, _x.camera_info.roi.width, _x.camera_info.roi.do_rectify, _x.cloud.header.seq, _x.cloud.header.stamp.secs, _x.cloud.header.stamp.nsecs,) = _get_struct_6IB3I().unpack(str[start:end])
      self.camera_info.roi.do_rectify = bool(self.camera_info.roi.do_rectify)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.cloud.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.cloud.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.cloud.height, _x.cloud.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.cloud.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1.name = str[start:end].decode('utf-8', 'rosmsg')
        else:
          val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _get_struct_IBI().unpack(str[start:end])
        self.cloud.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.cloud.is_bigendian, _x.cloud.point_step, _x.cloud.row_step,) = _get_struct_B2I().unpack(str[start:end])
      self.cloud.is_bigendian = bool(self.cloud.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.cloud.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.cloud.is_dense, _x.view_point.header.seq, _x.view_point.header.stamp.secs, _x.view_point.header.stamp.nsecs,) = _get_struct_B3I().unpack(str[start:end])
      self.cloud.is_dense = bool(self.cloud.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.view_point.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.view_point.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 115
      (_x.view_point.pose.position.x, _x.view_point.pose.position.y, _x.view_point.pose.position.z, _x.view_point.pose.orientation.x, _x.view_point.pose.orientation.y, _x.view_point.pose.orientation.z, _x.view_point.pose.orientation.w, _x.aruco_board.position.x, _x.aruco_board.position.y, _x.aruco_board.position.z, _x.aruco_board.orientation.x, _x.aruco_board.orientation.y, _x.aruco_board.orientation.z, _x.aruco_board.orientation.w, _x.grasp_filter_flag, _x.n_of_candidates,) = _get_struct_14dBh().unpack(str[start:end])
      self.grasp_filter_flag = bool(self.grasp_filter_flag)
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    :param buff: buffer, ``StringIO``
    :param numpy: numpy python module
    """
    try:
      _x = self
      buff.write(_get_struct_3I().pack(_x.color_image.header.seq, _x.color_image.header.stamp.secs, _x.color_image.header.stamp.nsecs))
      _x = self.color_image.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.color_image.height, _x.color_image.width))
      _x = self.color_image.encoding
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_BI().pack(_x.color_image.is_bigendian, _x.color_image.step))
      _x = self.color_image.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_3I().pack(_x.depth_image.header.seq, _x.depth_image.header.stamp.secs, _x.depth_image.header.stamp.nsecs))
      _x = self.depth_image.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.depth_image.height, _x.depth_image.width))
      _x = self.depth_image.encoding
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_BI().pack(_x.depth_image.is_bigendian, _x.depth_image.step))
      _x = self.depth_image.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_3I().pack(_x.seg_image.header.seq, _x.seg_image.header.stamp.secs, _x.seg_image.header.stamp.nsecs))
      _x = self.seg_image.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.seg_image.height, _x.seg_image.width))
      _x = self.seg_image.encoding
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_BI().pack(_x.seg_image.is_bigendian, _x.seg_image.step))
      _x = self.seg_image.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_3I().pack(_x.camera_info.header.seq, _x.camera_info.header.stamp.secs, _x.camera_info.header.stamp.nsecs))
      _x = self.camera_info.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.camera_info.height, _x.camera_info.width))
      _x = self.camera_info.distortion_model
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.camera_info.D)
      buff.write(_struct_I.pack(length))
      pattern = '<%sd'%length
      buff.write(self.camera_info.D.tostring())
      buff.write(self.camera_info.K.tostring())
      buff.write(self.camera_info.R.tostring())
      buff.write(self.camera_info.P.tostring())
      _x = self
      buff.write(_get_struct_6IB3I().pack(_x.camera_info.binning_x, _x.camera_info.binning_y, _x.camera_info.roi.x_offset, _x.camera_info.roi.y_offset, _x.camera_info.roi.height, _x.camera_info.roi.width, _x.camera_info.roi.do_rectify, _x.cloud.header.seq, _x.cloud.header.stamp.secs, _x.cloud.header.stamp.nsecs))
      _x = self.cloud.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.cloud.height, _x.cloud.width))
      length = len(self.cloud.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.cloud.fields:
        _x = val1.name
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = val1
        buff.write(_get_struct_IBI().pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_get_struct_B2I().pack(_x.cloud.is_bigendian, _x.cloud.point_step, _x.cloud.row_step))
      _x = self.cloud.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_B3I().pack(_x.cloud.is_dense, _x.view_point.header.seq, _x.view_point.header.stamp.secs, _x.view_point.header.stamp.nsecs))
      _x = self.view_point.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_14dBh().pack(_x.view_point.pose.position.x, _x.view_point.pose.position.y, _x.view_point.pose.position.z, _x.view_point.pose.orientation.x, _x.view_point.pose.orientation.y, _x.view_point.pose.orientation.z, _x.view_point.pose.orientation.w, _x.aruco_board.position.x, _x.aruco_board.position.y, _x.aruco_board.position.z, _x.aruco_board.orientation.x, _x.aruco_board.orientation.y, _x.aruco_board.orientation.z, _x.aruco_board.orientation.w, _x.grasp_filter_flag, _x.n_of_candidates))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    :param str: byte array of serialized message, ``str``
    :param numpy: numpy python module
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.color_image is None:
        self.color_image = sensor_msgs.msg.Image()
      if self.depth_image is None:
        self.depth_image = sensor_msgs.msg.Image()
      if self.seg_image is None:
        self.seg_image = sensor_msgs.msg.Image()
      if self.camera_info is None:
        self.camera_info = sensor_msgs.msg.CameraInfo()
      if self.cloud is None:
        self.cloud = sensor_msgs.msg.PointCloud2()
      if self.view_point is None:
        self.view_point = geometry_msgs.msg.PoseStamped()
      if self.aruco_board is None:
        self.aruco_board = geometry_msgs.msg.Pose()
      end = 0
      _x = self
      start = end
      end += 12
      (_x.color_image.header.seq, _x.color_image.header.stamp.secs, _x.color_image.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.color_image.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.color_image.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.color_image.height, _x.color_image.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.color_image.encoding = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.color_image.encoding = str[start:end]
      _x = self
      start = end
      end += 5
      (_x.color_image.is_bigendian, _x.color_image.step,) = _get_struct_BI().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.color_image.data = str[start:end]
      _x = self
      start = end
      end += 12
      (_x.depth_image.header.seq, _x.depth_image.header.stamp.secs, _x.depth_image.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.depth_image.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.depth_image.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.depth_image.height, _x.depth_image.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.depth_image.encoding = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.depth_image.encoding = str[start:end]
      _x = self
      start = end
      end += 5
      (_x.depth_image.is_bigendian, _x.depth_image.step,) = _get_struct_BI().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.depth_image.data = str[start:end]
      _x = self
      start = end
      end += 12
      (_x.seg_image.header.seq, _x.seg_image.header.stamp.secs, _x.seg_image.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.seg_image.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.seg_image.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.seg_image.height, _x.seg_image.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.seg_image.encoding = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.seg_image.encoding = str[start:end]
      _x = self
      start = end
      end += 5
      (_x.seg_image.is_bigendian, _x.seg_image.step,) = _get_struct_BI().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.seg_image.data = str[start:end]
      _x = self
      start = end
      end += 12
      (_x.camera_info.header.seq, _x.camera_info.header.stamp.secs, _x.camera_info.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.camera_info.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.camera_info.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.camera_info.height, _x.camera_info.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.camera_info.distortion_model = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.camera_info.distortion_model = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%sd'%length
      start = end
      s = struct.Struct(pattern)
      end += s.size
      self.camera_info.D = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=length)
      start = end
      end += 72
      self.camera_info.K = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=9)
      start = end
      end += 72
      self.camera_info.R = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=9)
      start = end
      end += 96
      self.camera_info.P = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=12)
      _x = self
      start = end
      end += 37
      (_x.camera_info.binning_x, _x.camera_info.binning_y, _x.camera_info.roi.x_offset, _x.camera_info.roi.y_offset, _x.camera_info.roi.height, _x.camera_info.roi.width, _x.camera_info.roi.do_rectify, _x.cloud.header.seq, _x.cloud.header.stamp.secs, _x.cloud.header.stamp.nsecs,) = _get_struct_6IB3I().unpack(str[start:end])
      self.camera_info.roi.do_rectify = bool(self.camera_info.roi.do_rectify)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.cloud.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.cloud.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.cloud.height, _x.cloud.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.cloud.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1.name = str[start:end].decode('utf-8', 'rosmsg')
        else:
          val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _get_struct_IBI().unpack(str[start:end])
        self.cloud.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.cloud.is_bigendian, _x.cloud.point_step, _x.cloud.row_step,) = _get_struct_B2I().unpack(str[start:end])
      self.cloud.is_bigendian = bool(self.cloud.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.cloud.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.cloud.is_dense, _x.view_point.header.seq, _x.view_point.header.stamp.secs, _x.view_point.header.stamp.nsecs,) = _get_struct_B3I().unpack(str[start:end])
      self.cloud.is_dense = bool(self.cloud.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.view_point.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.view_point.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 115
      (_x.view_point.pose.position.x, _x.view_point.pose.position.y, _x.view_point.pose.position.z, _x.view_point.pose.orientation.x, _x.view_point.pose.orientation.y, _x.view_point.pose.orientation.z, _x.view_point.pose.orientation.w, _x.aruco_board.position.x, _x.aruco_board.position.y, _x.aruco_board.position.z, _x.aruco_board.orientation.x, _x.aruco_board.orientation.y, _x.aruco_board.orientation.z, _x.aruco_board.orientation.w, _x.grasp_filter_flag, _x.n_of_candidates,) = _get_struct_14dBh().unpack(str[start:end])
      self.grasp_filter_flag = bool(self.grasp_filter_flag)
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill

_struct_I = genpy.struct_I
def _get_struct_I():
    global _struct_I
    return _struct_I
_struct_12d = None
def _get_struct_12d():
    global _struct_12d
    if _struct_12d is None:
        _struct_12d = struct.Struct("<12d")
    return _struct_12d
_struct_14dBh = None
def _get_struct_14dBh():
    global _struct_14dBh
    if _struct_14dBh is None:
        _struct_14dBh = struct.Struct("<14dBh")
    return _struct_14dBh
_struct_2I = None
def _get_struct_2I():
    global _struct_2I
    if _struct_2I is None:
        _struct_2I = struct.Struct("<2I")
    return _struct_2I
_struct_3I = None
def _get_struct_3I():
    global _struct_3I
    if _struct_3I is None:
        _struct_3I = struct.Struct("<3I")
    return _struct_3I
_struct_6IB3I = None
def _get_struct_6IB3I():
    global _struct_6IB3I
    if _struct_6IB3I is None:
        _struct_6IB3I = struct.Struct("<6IB3I")
    return _struct_6IB3I
_struct_9d = None
def _get_struct_9d():
    global _struct_9d
    if _struct_9d is None:
        _struct_9d = struct.Struct("<9d")
    return _struct_9d
_struct_B2I = None
def _get_struct_B2I():
    global _struct_B2I
    if _struct_B2I is None:
        _struct_B2I = struct.Struct("<B2I")
    return _struct_B2I
_struct_B3I = None
def _get_struct_B3I():
    global _struct_B3I
    if _struct_B3I is None:
        _struct_B3I = struct.Struct("<B3I")
    return _struct_B3I
_struct_BI = None
def _get_struct_BI():
    global _struct_BI
    if _struct_BI is None:
        _struct_BI = struct.Struct("<BI")
    return _struct_BI
_struct_IBI = None
def _get_struct_IBI():
    global _struct_IBI
    if _struct_IBI is None:
        _struct_IBI = struct.Struct("<IBI")
    return _struct_IBI
# This Python file uses the following encoding: utf-8
"""autogenerated by genpy from grasping_benchmarks_ros/GraspPlannerResponse.msg. Do not edit."""
import codecs
import sys
python3 = True if sys.hexversion > 0x03000000 else False
import genpy
import struct

import geometry_msgs.msg
import grasping_benchmarks_ros.msg
import std_msgs.msg

class GraspPlannerResponse(genpy.Message):
  _md5sum = "8ecca25f1fac69685b24c22092600e9d"
  _type = "grasping_benchmarks_ros/GraspPlannerResponse"
  _has_header = False  # flag to mark the presence of a Header object
  _full_text = """
# response params
BenchmarkGrasp[] grasp_candidates

================================================================================
MSG: grasping_benchmarks_ros/BenchmarkGrasp
# This message describes a 2-finger grasp configuration by its 6-DOF pose
# expressed wrt to the world reference frame, and the opening
# width of the robot hand.

geometry_msgs/PoseStamped pose # grasp pose

std_msgs/Float32 width # Required aperture (opening width) of the robot hand

std_msgs/Float32 score # Score assigned to the grasp by the classifier

================================================================================
MSG: geometry_msgs/PoseStamped
# A Pose with reference coordinate frame and timestamp
Header header
Pose pose

================================================================================
MSG: std_msgs/Header
# Standard metadata for higher-level stamped data types.
# This is generally used to communicate timestamped data 
# in a particular coordinate frame.
# 
# sequence ID: consecutively increasing ID 
uint32 seq
#Two-integer timestamp that is expressed as:
# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')
# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')
# time-handling sugar is provided by the client library
time stamp
#Frame this data is associated with
string frame_id

================================================================================
MSG: geometry_msgs/Pose
# A representation of pose in free space, composed of position and orientation. 
Point position
Quaternion orientation

================================================================================
MSG: geometry_msgs/Point
# This contains the position of a point in free space
float64 x
float64 y
float64 z

================================================================================
MSG: geometry_msgs/Quaternion
# This represents an orientation in free space in quaternion form.

float64 x
float64 y
float64 z
float64 w

================================================================================
MSG: std_msgs/Float32
float32 data"""
  __slots__ = ['grasp_candidates']
  _slot_types = ['grasping_benchmarks_ros/BenchmarkGrasp[]']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.

    The available fields are:
       grasp_candidates

    :param args: complete set of field values, in .msg order
    :param kwds: use keyword arguments corresponding to message field names
    to set specific fields.
    """
    if args or kwds:
      super(GraspPlannerResponse, self).__init__(*args, **kwds)
      # message fields cannot be None, assign default values for those that are
      if self.grasp_candidates is None:
        self.grasp_candidates = []
    else:
      self.grasp_candidates = []

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    :param buff: buffer, ``StringIO``
    """
    try:
      length = len(self.grasp_candidates)
      buff.write(_struct_I.pack(length))
      for val1 in self.grasp_candidates:
        _v1 = val1.pose
        _v2 = _v1.header
        _x = _v2.seq
        buff.write(_get_struct_I().pack(_x))
        _v3 = _v2.stamp
        _x = _v3
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v2.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _v4 = _v1.pose
        _v5 = _v4.position
        _x = _v5
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v6 = _v4.orientation
        _x = _v6
        buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
        _v7 = val1.width
        _x = _v7.data
        buff.write(_get_struct_f().pack(_x))
        _v8 = val1.score
        _x = _v8.data
        buff.write(_get_struct_f().pack(_x))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    :param str: byte array of serialized message, ``str``
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.grasp_candidates is None:
        self.grasp_candidates = None
      end = 0
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.grasp_candidates = []
      for i in range(0, length):
        val1 = grasping_benchmarks_ros.msg.BenchmarkGrasp()
        _v9 = val1.pose
        _v10 = _v9.header
        start = end
        end += 4
        (_v10.seq,) = _get_struct_I().unpack(str[start:end])
        _v11 = _v10.stamp
        _x = _v11
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v10.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v10.frame_id = str[start:end]
        _v12 = _v9.pose
        _v13 = _v12.position
        _x = _v13
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v14 = _v12.orientation
        _x = _v14
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
        _v15 = val1.width
        start = end
        end += 4
        (_v15.data,) = _get_struct_f().unpack(str[start:end])
        _v16 = val1.score
        start = end
        end += 4
        (_v16.data,) = _get_struct_f().unpack(str[start:end])
        self.grasp_candidates.append(val1)
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    :param buff: buffer, ``StringIO``
    :param numpy: numpy python module
    """
    try:
      length = len(self.grasp_candidates)
      buff.write(_struct_I.pack(length))
      for val1 in self.grasp_candidates:
        _v17 = val1.pose
        _v18 = _v17.header
        _x = _v18.seq
        buff.write(_get_struct_I().pack(_x))
        _v19 = _v18.stamp
        _x = _v19
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v18.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _v20 = _v17.pose
        _v21 = _v20.position
        _x = _v21
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v22 = _v20.orientation
        _x = _v22
        buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
        _v23 = val1.width
        _x = _v23.data
        buff.write(_get_struct_f().pack(_x))
        _v24 = val1.score
        _x = _v24.data
        buff.write(_get_struct_f().pack(_x))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    :param str: byte array of serialized message, ``str``
    :param numpy: numpy python module
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.grasp_candidates is None:
        self.grasp_candidates = None
      end = 0
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.grasp_candidates = []
      for i in range(0, length):
        val1 = grasping_benchmarks_ros.msg.BenchmarkGrasp()
        _v25 = val1.pose
        _v26 = _v25.header
        start = end
        end += 4
        (_v26.seq,) = _get_struct_I().unpack(str[start:end])
        _v27 = _v26.stamp
        _x = _v27
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v26.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v26.frame_id = str[start:end]
        _v28 = _v25.pose
        _v29 = _v28.position
        _x = _v29
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v30 = _v28.orientation
        _x = _v30
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
        _v31 = val1.width
        start = end
        end += 4
        (_v31.data,) = _get_struct_f().unpack(str[start:end])
        _v32 = val1.score
        start = end
        end += 4
        (_v32.data,) = _get_struct_f().unpack(str[start:end])
        self.grasp_candidates.append(val1)
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill

_struct_I = genpy.struct_I
def _get_struct_I():
    global _struct_I
    return _struct_I
_struct_2I = None
def _get_struct_2I():
    global _struct_2I
    if _struct_2I is None:
        _struct_2I = struct.Struct("<2I")
    return _struct_2I
_struct_3d = None
def _get_struct_3d():
    global _struct_3d
    if _struct_3d is None:
        _struct_3d = struct.Struct("<3d")
    return _struct_3d
_struct_4d = None
def _get_struct_4d():
    global _struct_4d
    if _struct_4d is None:
        _struct_4d = struct.Struct("<4d")
    return _struct_4d
_struct_f = None
def _get_struct_f():
    global _struct_f
    if _struct_f is None:
        _struct_f = struct.Struct("<f")
    return _struct_f
class GraspPlanner(object):
  _type          = 'grasping_benchmarks_ros/GraspPlanner'
  _md5sum = 'ceda0dc2581a41231dd96a6a9bba18c1'
  _request_class  = GraspPlannerRequest
  _response_class = GraspPlannerResponse
