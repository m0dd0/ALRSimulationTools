{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 28 2022 16:12:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Since Open3D 0.15, installing Open3D via conda is deprecated. Please re-install Open3D via: `pip install open3d -U`.\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import importlib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import rospy\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "\n",
    "from alr_sim.sims.SimFactory import SimRepository\n",
    "from alr_sim.core import Scene\n",
    "from alr_sim.sims.universal_sim.PrimitiveObjects import Box\n",
    "from alr_sim.sims.mj_beta import MjCamera\n",
    "\n",
    "from alr_simulation_tools.ycb_utils import YCBLoader\n",
    "from alr_simulation_tools.scene_utils import execute_grasping_sequence, create_sample_data, reset_scene\n",
    "\n",
    "import ros_numpy\n",
    "from grasping_benchmarks_ros.srv import (\n",
    "    GraspPlanner,\n",
    "    GraspPlannerRequest,\n",
    "    GraspPlannerResponse,\n",
    ")\n",
    "\n",
    "from grasp_benchmark.utils.ros_utils import (\n",
    "    transform_pc,\n",
    "    create_grasp_planner_request,\n",
    "    calc_point_cloud_from_images\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scene parameters\n",
    "\n",
    "factory_string = \"mj_beta\"\n",
    "object_pos = (0.5, 0.0, 0.2)\n",
    "adhust_object_position = True\n",
    "cam_pos = (0.5, 0.0, 1)\n",
    "cam_quat = [0.7071067811865476, 0.0, 0.0, -0.7071067811865475]\n",
    "# cam_quat = R.from_euler(\"xyz\", (0, 0, -90), degrees=True).as_quat()[\n",
    "#         [3, 0, 1, 2]\n",
    "#     ].tolist(),\n",
    "# cam_quat = R.from_euler(\"zyx\", (-90, -30, 0), degrees=True).as_quat()[\n",
    "#         [3, 0, 1, 2]\n",
    "#     ].tolist(),\n",
    "# cam_quat = (\n",
    "#     R.from_euler(\"zyx\", (90, 50, 0), degrees=True).as_quat()[[3, 0, 1, 2]].tolist()\n",
    "# )\n",
    "cam_height = 480\n",
    "cam_width = 640\n",
    "robot_pos = (0.0, 0.5, 0.2)\n",
    "robot_quat = (0, 1, 0, 0)\n",
    "render_mode = Scene.RenderMode.HUMAN    \n",
    "wait_time = 0.5\n",
    "move_duration = 2\n",
    "\n",
    "#\n",
    "grasp_planner_service_id = \"grconvnet_bench/grconvnet_grasp_planner_service\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objects in the scene\n",
    "ycb_loader = YCBLoader(\n",
    "    ycb_base_folder=Path.home() / \"Documents\" / \"ycb\", factory_string=factory_string\n",
    ")\n",
    "\n",
    "sim_obj, obj_name = ycb_loader.get_ycb_object(\n",
    "    index=0, adjust_object_position=adhust_object_position, pos=object_pos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node(\"grasp_planner_client\")\n",
    "\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting\")\n",
    "for i in range(len(ycb_loader)):\n",
    "# for i in [1]:\n",
    "    if ycb_loader.is_broken(i):\n",
    "        logging.info(f\"Skipping broken object {ycb_loader.get_obj_name(i)}\")\n",
    "        continue\n",
    "    logging.info(f\"Creating sample data for {ycb_loader.get_obj_name(i)}\")\n",
    "\n",
    "\n",
    "    sim_obj, name = ycb_loader.get_ycb_object(\n",
    "        index=i, adjust_object_position=adhust_object_position, pos=object_pos\n",
    "    )\n",
    "\n",
    "    results, scene, agent = create_sample_data(\n",
    "        factory_string=factory_string,\n",
    "        cam_pos=cam_pos,\n",
    "        cam_quat=cam_quat,\n",
    "        cam_height=cam_height,\n",
    "        cam_width=cam_width,\n",
    "        robot_pos=robot_pos,\n",
    "        robot_quat=robot_quat,\n",
    "        object_list=[sim_obj],\n",
    "        target_obj_name=name,\n",
    "        render_mode=render_mode,\n",
    "        wait_time=wait_time,\n",
    "        move_duration=move_duration,\n",
    "    )\n",
    "    logging.info(\"Sample data created\")\n",
    "\n",
    "    pc_points, pc_colors = calc_point_cloud_from_images(\n",
    "        rgb_img=results[\"rgb_img\"], depth_img=results[\"depth_img\"], cam_intrinsics=results[\"cam_intrinsics\"]\n",
    "    )\n",
    "\n",
    "    grasp_req = create_grasp_planner_request(\n",
    "        rgb_img=results[\"rgb_img\"],\n",
    "        depth_img=results[\"depth_img\"],\n",
    "        seg_img=results[\"seg_img\"],\n",
    "        pc_points=pc_points,\n",
    "        pc_colors=pc_colors,\n",
    "        cam_pos=results[\"cam_pos\"],\n",
    "        cam_quat=results[\"cam_quat\"],\n",
    "        cam_intrinsics=results[\"cam_intrinsics\"],\n",
    "        cam_height=cam_height,\n",
    "        cam_width=cam_width,\n",
    "        num_of_candidates=10_000,\n",
    "    )\n",
    "\n",
    "    rospy.wait_for_service(grasp_planner_service_id, timeout=30.0)\n",
    "    grasp_planner = rospy.ServiceProxy(grasp_planner_service_id, GraspPlanner)\n",
    "\n",
    "    reply: GraspPlannerResponse = grasp_planner(grasp_req)\n",
    "    logging.info(\"Received grasp candidates\")\n",
    "\n",
    "    best_grasp = sorted(reply.grasp_candidates, key=lambda x: x.score.data)[-1]\n",
    "    grasp_pos = best_grasp.pose.pose.position\n",
    "    grasp_pos = (grasp_pos.x, grasp_pos.y, grasp_pos.z)\n",
    "    grasp_quat = best_grasp.pose.pose.orientation\n",
    "    grasp_quat = (grasp_quat.w, grasp_quat.x, grasp_quat.y, grasp_quat.z)\n",
    "\n",
    "    execute_grasping_sequence(\n",
    "        agent = agent,\n",
    "        grasp_pos = grasp_pos,\n",
    "        grasp_quat = grasp_quat\n",
    "    )\n",
    "\n",
    "    reset_scene(factory_string, scene, agent)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96361501184a06229a7d6ad5729629afa32655127681c80903108d359eca8b02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
