{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demonstration of the fulle procedure to use a grasping service to execute a grap on a loaded ycb object. \n",
    "The procedure is the following:\n",
    "\n",
    "1.) \n",
    "\n",
    "To successfully execute this notebook, a roscore needs to be running on the same machine as the notebook server and the grasping service needs to be running.\n",
    "The grasping services from the `grasping-benchmark-panda` repo can be easily started using the Docker containers provided in the `grasping-benchmark-panda` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May  2 2023 05:55:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Could not import grasping_benchmarks_ros\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import importlib\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "\n",
    "from alr_sim.core import Scene\n",
    "\n",
    "from alr_simulation_tools.ycb_utils import YCBLoader\n",
    "from alr_simulation_tools.scene_utils import execute_grasping_sequence, record_camera_data, reset_scene\n",
    "from alr_simulation_tools.ros_utils import create_grasp_planner_request\n",
    "\n",
    "import rospy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTORY_STRING = \"mj_beta\"\n",
    "OBJECT_POS = (0.5, 0.0, 0.2)\n",
    "CAM_POS = (0.5, 0.0, 1)\n",
    "CAM_QUAT = [0.7071067811865476, 0.0, 0.0, -0.7071067811865475]\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "INITIAL_ROBOT_POS = (0.0, 0.5, 0.2)\n",
    "INITIAL_ROBOT_QUAT = (0, 1, 0, 0)\n",
    "RENDER_MODE = Scene.RenderMode.HUMAN    \n",
    "DATA_RECORDING_WAIT_TIME = 0.5\n",
    "DATA_RECORDING_MOVE_TIME = 2\n",
    "\n",
    "GRASP_PLANNER_SERVICE_ID = \"contact_graspnet_bench/contact_graspnet_grasp_planner_service\"\n",
    "\n",
    "YCB_FOLDER = Path.home() / \"Documents\" / \"SF-ObjectDataset\" / \"YCB\"\n",
    "YCB_OBJECT_ID = \"011_banana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycb_loader = YCBLoader(ycb_base_folder=YCB_FOLDER, factory_string=\"mj_beta\")\n",
    "\n",
    "sim_obj = ycb_loader.get_ycb_object(\n",
    "    pos=(0.5, 0.0, 0.2), quat=(0, 1, 0, 0), obj_id=YCB_OBJECT_ID, name=YCB_OBJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: mju_openResource: could not open resource '/home/moritz/Documents/SimulationFramework/models/mj/robot/panda_tmp_rb0_e945af24-a7d3-11ee-aa82-c8ff282b54dd.xml' with default provider at slot 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera_data, scene, agent = record_camera_data(\n",
    "    factory_string=FACTORY_STRING,\n",
    "    cam_pos=CAM_POS,\n",
    "    cam_quat=CAM_QUAT,\n",
    "    cam_height=CAM_HEIGHT,\n",
    "    cam_width=CAM_WIDTH,\n",
    "    robot_pos=INITIAL_ROBOT_POS,\n",
    "    robot_quat=INITIAL_ROBOT_QUAT,\n",
    "    object_list=[sim_obj],\n",
    "    target_obj_name=YCB_OBJECT_ID,\n",
    "    render_mode=RENDER_MODE,\n",
    "    wait_time=DATA_RECORDING_WAIT_TIME,\n",
    "    move_duration=DATA_RECORDING_MOVE_TIME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node(\"grasp_planner_client\")\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Could not import grasping_benchmarks_ros",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grasp_req \u001b[39m=\u001b[39m create_grasp_planner_request(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     rgb_img\u001b[39m=\u001b[39;49mcamera_data[\u001b[39m\"\u001b[39;49m\u001b[39mrgb_img\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     depth_img\u001b[39m=\u001b[39;49mcamera_data[\u001b[39m\"\u001b[39;49m\u001b[39mdepth_img\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     seg_img\u001b[39m=\u001b[39;49mcamera_data[\u001b[39m\"\u001b[39;49m\u001b[39mseg_img\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pc_points\u001b[39m=\u001b[39;49mcamera_data[\u001b[39m\"\u001b[39;49m\u001b[39mpoint_cloud\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     pc_colors\u001b[39m=\u001b[39;49mcamera_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     cam_pos\u001b[39m=\u001b[39;49mcamera_data[\u001b[39m\"\u001b[39;49m\u001b[39mcam_pos\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     cam_quat\u001b[39m=\u001b[39;49mcamera_data[\u001b[39m\"\u001b[39;49m\u001b[39mcam_quat\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     cam_intrinsics\u001b[39m=\u001b[39;49mcamera_data[\u001b[39m\"\u001b[39;49m\u001b[39mcam_intrinsics\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     cam_height\u001b[39m=\u001b[39;49mCAM_HEIGHT,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     cam_width\u001b[39m=\u001b[39;49mCAM_WIDTH,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     num_of_candidates\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/moritz/Documents/ALRSimulationTools/notebooks/grasping_rosservice_from_simulation.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ALRSimulationTools/alr_simulation_tools/ros_utils.py:222\u001b[0m, in \u001b[0;36mcreate_grasp_planner_request\u001b[0;34m(rgb_img, depth_img, seg_img, pc_points, pc_colors, cam_pos, cam_quat, cam_intrinsics, cam_height, cam_width, num_of_candidates)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_grasp_planner_request\u001b[39m(\n\u001b[1;32m    195\u001b[0m     rgb_img: NpArray[\u001b[39m\"\u001b[39m\u001b[39mH,W,3\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mfloat\u001b[39m],\n\u001b[1;32m    196\u001b[0m     depth_img: NpArray[\u001b[39m\"\u001b[39m\u001b[39mH,W\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mfloat\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     num_of_candidates: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m    206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m GraspPlannerRequest:\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m    Create a GraspPlannerRequest ROS message from all necessary data\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m    :param rgb_img: RGB image in width,height,rgb\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39m    :return: GraspPlannerRequest ROS message\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39massert\u001b[39;00m GraspPlannerRequest \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mCould not import grasping_benchmarks_ros\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m     planner_req \u001b[39m=\u001b[39m GraspPlannerRequest()\n\u001b[1;32m    226\u001b[0m     header \u001b[39m=\u001b[39m Header()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Could not import grasping_benchmarks_ros"
     ]
    }
   ],
   "source": [
    "grasp_req = create_grasp_planner_request(\n",
    "    rgb_img=camera_data[\"rgb_img\"],\n",
    "    depth_img=camera_data[\"depth_img\"],\n",
    "    seg_img=camera_data[\"seg_img\"],\n",
    "    pc_points=camera_data[\"point_cloud\"],\n",
    "    pc_colors=camera_data,\n",
    "    cam_pos=camera_data[\"cam_pos\"],\n",
    "    cam_quat=camera_data[\"cam_quat\"],\n",
    "    cam_intrinsics=camera_data[\"cam_intrinsics\"],\n",
    "    cam_height=CAM_HEIGHT,\n",
    "    cam_width=CAM_WIDTH,\n",
    "    num_of_candidates=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.wait_for_service(GRASP_PLANNER_SERVICE_ID, timeout=30.0)\n",
    "grasp_planner = rospy.ServiceProxy(GRASP_PLANNER_SERVICE_ID, GraspPlanner)\n",
    "\n",
    "reply: GraspPlannerResponse = grasp_planner(grasp_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grasp = sorted(reply.grasp_candidates, key=lambda x: x.score.data)[-1]\n",
    "\n",
    "grasp_pos = best_grasp.pose.pose.position\n",
    "grasp_pos = np.array((grasp_pos.x, grasp_pos.y, grasp_pos.z))\n",
    "\n",
    "grasp_quat = best_grasp.pose.pose.orientation\n",
    "grasp_quat = np.array((grasp_quat.w, grasp_quat.x, grasp_quat.y, grasp_quat.z))\n",
    "\n",
    "grasp_rot = R.from_quat(grasp_quat[[1,2,3,0]]).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grasp_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hover_pos = grasp_pos + np.array([0, 0, 0.2])\n",
    "# agent.gotoCartPositionAndQuat(hover_pos, grasp_quat)\n",
    "# agent.wait(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "execute_grasping_sequence(\n",
    "    agent = agent,\n",
    "    grasp_pos = grasp_pos,\n",
    "    grasp_quat = grasp_quat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_scene(FACTORY_STRING, scene, agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648fd5414dd759cf455503f1ca8a8d1f6103f81afa3f898375d059feb8b10734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
