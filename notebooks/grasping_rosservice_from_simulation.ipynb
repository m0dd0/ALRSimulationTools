{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook contains a demonstration of the fulle procedure to use a grasping service to execute a grap on a loaded ycb object. \n",
                "The procedure is the following:\n",
                "\n",
                "1.) load an yccb object\n",
                "\n",
                "2.) put the object into the simulated scene and take a picture from a defined viewpoint\n",
                "\n",
                "3.) create a grasp planner request from the recorded data\n",
                "\n",
                "4.) send the request to the ROS grasping service\n",
                "\n",
                "5.) wait for the result and decompose it\n",
                "\n",
                "6.) execute a grasping sequence based on the decomposed result\n",
                "\n",
                "To successfully execute this notebook, the grasping service needs to be running.\n",
                "The grasping services from the `grasping-benchmark-panda` repo can be easily started using the Docker containers provided in the `grasping-benchmark-panda` repo. \n",
                "Simply run `docker-compose -f <path-to-grasping-benchmark-panda/docker/build/docker-compose.yaml> up <name-of-the-grasp-algo>`. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import logging\n",
                "import importlib\n",
                "import sys\n",
                "\n",
                "from scipy.spatial.transform import Rotation as R\n",
                "import numpy as np\n",
                "\n",
                "from alr_sim.core import Scene\n",
                "\n",
                "from alr_sim_tools.ycb_utils import YCBLoader\n",
                "from alr_sim_tools.scene_utils import (\n",
                "    execute_grasping_sequence,\n",
                "    record_camera_data,\n",
                "    reset_scene,\n",
                ")\n",
                "from alr_sim_tools.ros_utils import create_grasp_planner_request\n",
                "\n",
                "sys.path.append(str(Path.cwd().parent / \"alr_sim_tools\" / \"ros_msg_srv_definitions\"))\n",
                "from alr_sim_tools.ros_msg_srv_definitions.grasping_benchmarks_ros.srv import (\n",
                "    GraspPlannerResponse,\n",
                "    GraspPlanner,\n",
                ")\n",
                "\n",
                "import rospy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "FACTORY_STRING = \"mj_beta\"\n",
                "OBJECT_POS = (0.5, 0.0, 0.2)\n",
                "CAM_POS = (0.5, 0.0, 1)\n",
                "CAM_QUAT = [0.7071067811865476, 0.0, 0.0, -0.7071067811865475]\n",
                "CAM_HEIGHT = 480\n",
                "CAM_WIDTH = 640\n",
                "INITIAL_ROBOT_POS = (0.0, 0.5, 0.2)\n",
                "INITIAL_ROBOT_QUAT = (0, 1, 0, 0)\n",
                "RENDER_MODE = Scene.RenderMode.HUMAN    \n",
                "\n",
                "GRASP_PLANNER_SERVICE_ID = f\"se3dif/Se3DifGraspPlanner_service\"\n",
                "\n",
                "YCB_FOLDER = Path.home() / \"Documents\" / \"SF-ObjectDataset\" / \"YCB\"\n",
                "YCB_OBJECT_ID = \"011_banana\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "ycb_loader = YCBLoader(ycb_base_folder=YCB_FOLDER, factory_string=\"mj_beta\")\n",
                "\n",
                "sim_obj = ycb_loader.get_ycb_object(\n",
                "    pos=OBJECT_POS, quat=(0, 1, 0, 0), object_id=YCB_OBJECT_ID, name=YCB_OBJECT_ID, grounded=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING: mju_openResource: could not open resource '/home/moritz_hesche/Documents/SimulationFramework/models/mj/robot/panda_tmp_rb1_c7804fe0-0d5c-11ef-9e8a-d45d647c35aa.xml' with default provider at slot 1\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/moritz_hesche/miniconda3/envs/alr_tools/lib/python3.9/site-packages/glfw/__init__.py:914: GLFWError: (65546) b'Cannot make current with a window that has no OpenGL or OpenGL ES context'\n",
                        "  warnings.warn(message, GLFWError)\n"
                    ]
                }
            ],
            "source": [
                "camera_data, scene, agent = record_camera_data(\n",
                "    factory_string=FACTORY_STRING,\n",
                "    camera_position=CAM_POS,\n",
                "    camera_quaternion=CAM_QUAT,\n",
                "    camera_height=CAM_HEIGHT,\n",
                "    camera_width=CAM_WIDTH,\n",
                "    robot_position=INITIAL_ROBOT_POS,\n",
                "    robot_quaternion=INITIAL_ROBOT_QUAT,\n",
                "    object_list=[sim_obj],\n",
                "    target_object_name=YCB_OBJECT_ID,\n",
                "    render_mode=RENDER_MODE,\n",
                "    wait_time=1,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "rospy.init_node(\"grasp_planner_client\")\n",
                "importlib.reload(logging)\n",
                "logging.basicConfig(level=logging.INFO)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "grasp_req = create_grasp_planner_request(\n",
                "    camera_data=camera_data,\n",
                "    number_of_candidates=1,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "rospy.wait_for_service(GRASP_PLANNER_SERVICE_ID, timeout=30.0)\n",
                "grasp_planner = rospy.ServiceProxy(GRASP_PLANNER_SERVICE_ID, GraspPlanner)\n",
                "\n",
                "reply: GraspPlannerResponse = grasp_planner(grasp_req)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_grasp = sorted(reply.grasp_candidates, key=lambda x: x.score.data)[-1]\n",
                "\n",
                "grasp_pos = best_grasp.pose.pose.position\n",
                "grasp_pos = np.array((grasp_pos.x, grasp_pos.y, grasp_pos.z))\n",
                "\n",
                "grasp_quat = best_grasp.pose.pose.orientation\n",
                "grasp_quat = np.array((grasp_quat.w, grasp_quat.x, grasp_quat.y, grasp_quat.z))\n",
                "\n",
                "grasp_rot = R.from_quat(grasp_quat[[1,2,3,0]]).as_matrix()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:root:Beam to hover_ position [-761.78210444 -134.60259037 3148.5002464 ]\n",
                        "WARNING:root:Joint configuration for position [-761.78210444 -134.60259037 3148.5002464 ] and quaternion [-0.17760095  0.33193842 -0.51033803  0.7731946 ] not found. Moving to position and saving joint configuration.\n",
                        "INFO:root:Opening gripper\n",
                        "INFO:root:Going to grasp position [-761.74737549 -134.63615417 3148.51318359]\n",
                        "INFO:root:Closing gripper\n",
                        "INFO:root:Going to hover position [-761.78210444 -134.60259037 3148.5002464 ]\n",
                        "INFO:root:Going to drop position (0, 0.5, 0.5)\n",
                        "INFO:root:Opening gripper\n"
                    ]
                }
            ],
            "source": [
                "execute_grasping_sequence(\n",
                "    agent = agent,\n",
                "    grasp_position = grasp_pos,\n",
                "    grasp_quaternion = grasp_quat\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "reset_scene(FACTORY_STRING, scene, agent)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ggcnn",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "648fd5414dd759cf455503f1ca8a8d1f6103f81afa3f898375d059feb8b10734"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
