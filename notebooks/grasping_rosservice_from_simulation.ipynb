{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook contains a demonstration of the fulle procedure to use a grasping service to execute a grap on a loaded ycb object. \n",
                "The procedure is the following:\n",
                "\n",
                "1.) load an yccb object\n",
                "\n",
                "2.) put the object into the simulated scene and take a picture from a defined viewpoint\n",
                "\n",
                "3.) create a grasp planner request from the recorded data\n",
                "\n",
                "4.) send the request to the ROS grasping service\n",
                "\n",
                "5.) wait for the result and decompose it\n",
                "\n",
                "6.) execute a grasping sequence based on the decomposed result\n",
                "\n",
                "To successfully execute this notebook, the grasping service needs to be running.\n",
                "The grasping services from the `grasping-benchmark-panda` repo can be easily started using the Docker containers provided in the `grasping-benchmark-panda` repo. \n",
                "Simply run `docker-compose -f <path-to-grasping-benchmark-panda/docker/build/docker-compose.yaml> up <name-of-the-grasp-algo>`. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import logging\n",
                "import importlib\n",
                "import sys\n",
                "\n",
                "from scipy.spatial.transform import Rotation as R\n",
                "import numpy as np\n",
                "\n",
                "from alr_sim.core import Scene\n",
                "\n",
                "from alr_sim_tools.ycb_utils import YCBLoader\n",
                "from alr_sim_tools.scene_utils import (\n",
                "    execute_grasping_sequence,\n",
                "    record_camera_data,\n",
                "    reset_scene,\n",
                ")\n",
                "from alr_sim_tools.ros_utils import create_grasp_planner_request\n",
                "\n",
                "sys.path.append(str(Path.cwd().parent / \"alr_sim_tools\" / \"ros_msg_srv_definitions\"))\n",
                "from alr_sim_tools.ros_msg_srv_definitions.grasping_benchmarks_ros.srv import (\n",
                "    GraspPlannerResponse,\n",
                "    GraspPlanner,\n",
                ")\n",
                "\n",
                "import rospy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "FACTORY_STRING = \"mj_beta\"\n",
                "OBJECT_POS = (0.5, 0.0, 0.2)\n",
                "CAM_POS = (0.5, 0.0, 1)\n",
                "CAM_QUAT = [0.7071067811865476, 0.0, 0.0, -0.7071067811865475]\n",
                "CAM_HEIGHT = 480\n",
                "CAM_WIDTH = 640\n",
                "INITIAL_ROBOT_POS = (0.0, 0.5, 0.2)\n",
                "INITIAL_ROBOT_QUAT = (0, 1, 0, 0)\n",
                "RENDER_MODE = Scene.RenderMode.HUMAN    \n",
                "\n",
                "GRASP_ALGO_NAME = \"grconvnet\"\n",
                "GRASP_PLANNER_SERVICE_ID = f\"{GRASP_ALGO_NAME}_bench/{GRASP_ALGO_NAME}_grasp_planner_service\"\n",
                "\n",
                "YCB_FOLDER = Path.home() / \"Documents\" / \"SF-ObjectDataset\" / \"YCB\"\n",
                "YCB_OBJECT_ID = \"011_banana\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ycb_loader = YCBLoader(ycb_base_folder=YCB_FOLDER, factory_string=\"mj_beta\")\n",
                "\n",
                "sim_obj = ycb_loader.get_ycb_object(\n",
                "    pos=OBJECT_POS, quat=(0, 1, 0, 0), obj_id=YCB_OBJECT_ID, name=YCB_OBJECT_ID, grounded=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "camera_data, scene, agent = record_camera_data(\n",
                "    factory_string=FACTORY_STRING,\n",
                "    cam_pos=CAM_POS,\n",
                "    cam_quat=CAM_QUAT,\n",
                "    cam_height=CAM_HEIGHT,\n",
                "    cam_width=CAM_WIDTH,\n",
                "    robot_pos=INITIAL_ROBOT_POS,\n",
                "    robot_quat=INITIAL_ROBOT_QUAT,\n",
                "    object_list=[sim_obj],\n",
                "    target_obj_name=YCB_OBJECT_ID,\n",
                "    render_mode=RENDER_MODE,\n",
                "    wait_time=1,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rospy.init_node(\"grasp_planner_client\")\n",
                "importlib.reload(logging)\n",
                "logging.basicConfig(level=logging.INFO)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "grasp_req = create_grasp_planner_request(\n",
                "    rgb_img=camera_data.rgb_img,\n",
                "    depth_img=camera_data.depth_img,\n",
                "    seg_img=camera_data.seg_img,\n",
                "    pc_points=camera_data.pointcloud_points,\n",
                "    pc_colors=camera_data.pointcloud_colors,\n",
                "    cam_pos=camera_data.cam_pos,\n",
                "    cam_quat=camera_data.cam_quat,\n",
                "    cam_intrinsics=camera_data.cam_intrinsics,\n",
                "    cam_height=CAM_HEIGHT,\n",
                "    cam_width=CAM_WIDTH,\n",
                "    num_of_candidates=1,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rospy.wait_for_service(GRASP_PLANNER_SERVICE_ID, timeout=30.0)\n",
                "grasp_planner = rospy.ServiceProxy(GRASP_PLANNER_SERVICE_ID, GraspPlanner)\n",
                "\n",
                "reply: GraspPlannerResponse = grasp_planner(grasp_req)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_grasp = sorted(reply.grasp_candidates, key=lambda x: x.score.data)[-1]\n",
                "\n",
                "grasp_pos = best_grasp.pose.pose.position\n",
                "grasp_pos = np.array((grasp_pos.x, grasp_pos.y, grasp_pos.z))\n",
                "\n",
                "grasp_quat = best_grasp.pose.pose.orientation\n",
                "grasp_quat = np.array((grasp_quat.w, grasp_quat.x, grasp_quat.y, grasp_quat.z))\n",
                "\n",
                "grasp_rot = R.from_quat(grasp_quat[[1,2,3,0]]).as_matrix()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "execute_grasping_sequence(\n",
                "    agent = agent,\n",
                "    grasp_pos = grasp_pos,\n",
                "    grasp_quat = grasp_quat\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "reset_scene(FACTORY_STRING, scene, agent)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ggcnn",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "648fd5414dd759cf455503f1ca8a8d1f6103f81afa3f898375d059feb8b10734"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}