{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demonstration of the fulle procedure to use a grasping service to execute a grap on a loaded ycb object. \n",
    "The procedure is the following:\n",
    "\n",
    "1.) load an yccb object\n",
    "\n",
    "2.) put the object into the simulated scene and take a picture from a defined viewpoint\n",
    "\n",
    "3.) create a grasp planner request from the recorded data\n",
    "\n",
    "4.) send the request to the ROS grasping service\n",
    "\n",
    "5.) wait for the result and decompose it\n",
    "\n",
    "6.) execute a grasping sequence based on the decomposed result\n",
    "\n",
    "To successfully execute this notebook, a roscore needs to be running on the same machine as the notebook server and the grasping service needs to be running.\n",
    "The grasping services from the `grasping-benchmark-panda` repo can be easily started using the Docker containers provided in the `grasping-benchmark-panda` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May  2 2023 05:55:04\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "\n",
    "from alr_sim.core import Scene\n",
    "\n",
    "from alr_sim_tools.ycb_utils import YCBLoader\n",
    "from alr_sim_tools.scene_utils import (\n",
    "    execute_grasping_sequence,\n",
    "    record_camera_data,\n",
    "    reset_scene,\n",
    ")\n",
    "from alr_sim_tools.ros_utils import create_grasp_planner_request\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent / \"alr_sim_tools\" / \"ros_msg_srv_definitions\"))\n",
    "from alr_sim_tools.ros_msg_srv_definitions.grasping_benchmarks_ros.srv import (\n",
    "    GraspPlannerResponse,\n",
    "    GraspPlanner,\n",
    ")\n",
    "\n",
    "import rospy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTORY_STRING = \"mj_beta\"\n",
    "OBJECT_POS = (0.5, 0.0, 0.2)\n",
    "CAM_POS = (0.5, 0.0, 1)\n",
    "CAM_QUAT = [0.7071067811865476, 0.0, 0.0, -0.7071067811865475]\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "INITIAL_ROBOT_POS = (0.0, 0.5, 0.2)\n",
    "INITIAL_ROBOT_QUAT = (0, 1, 0, 0)\n",
    "RENDER_MODE = Scene.RenderMode.HUMAN    \n",
    "DATA_RECORDING_WAIT_TIME = 0.0\n",
    "DATA_RECORDING_MOVE_TIME = 2\n",
    "\n",
    "GRASP_PLANNER_SERVICE_ID = \"contact_bench/contact_grasp_planner_service\"\n",
    "\n",
    "YCB_FOLDER = Path.home() / \"Documents\" / \"SF-ObjectDataset\" / \"YCB\"\n",
    "YCB_OBJECT_ID = \"011_banana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycb_loader = YCBLoader(ycb_base_folder=YCB_FOLDER, factory_string=\"mj_beta\")\n",
    "\n",
    "sim_obj = ycb_loader.get_ycb_object(\n",
    "    pos=(0.5, 0.0, 0.2), quat=(0, 1, 0, 0), obj_id=YCB_OBJECT_ID, name=YCB_OBJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: mju_openResource: could not open resource '/home/moritz/Documents/SimulationFramework/models/mj/robot/panda_tmp_rb0_1e1c6150-c4f5-11ee-9956-c8ff282b54dd.xml' with default provider at slot 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera_data, scene, agent = record_camera_data(\n",
    "    factory_string=FACTORY_STRING,\n",
    "    cam_pos=CAM_POS,\n",
    "    cam_quat=CAM_QUAT,\n",
    "    cam_height=CAM_HEIGHT,\n",
    "    cam_width=CAM_WIDTH,\n",
    "    robot_pos=INITIAL_ROBOT_POS,\n",
    "    robot_quat=INITIAL_ROBOT_QUAT,\n",
    "    object_list=[sim_obj],\n",
    "    target_obj_name=YCB_OBJECT_ID,\n",
    "    render_mode=RENDER_MODE,\n",
    "    wait_time=DATA_RECORDING_WAIT_TIME,\n",
    "    move_duration=DATA_RECORDING_MOVE_TIME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to register with master node [http://localhost:11311]: master may not be running yet. Will keep trying.\n"
     ]
    },
    {
     "ename": "ROSInitException",
     "evalue": "Failed to initialize time. Please check logs for additional details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mROSInitException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrospy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrasp_planner_client\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(logging)\n\u001b[1;32m      3\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "File \u001b[0;32m~/miniconda3/envs/alr_tools/lib/python3.9/site-packages/rospy/client.py:336\u001b[0m, in \u001b[0;36minit_node\u001b[0;34m(name, argv, anonymous, log_level, disable_rostime, disable_rosout, disable_signals, xmlrpc_port, tcpros_port)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m disable_rostime:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rospy\u001b[38;5;241m.\u001b[39mimpl\u001b[38;5;241m.\u001b[39msimtime\u001b[38;5;241m.\u001b[39minit_simtime():\n\u001b[0;32m--> 336\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m rospy\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mROSInitException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to initialize time. Please check logs for additional details\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     rospy\u001b[38;5;241m.\u001b[39mrostime\u001b[38;5;241m.\u001b[39mset_rostime_initialized(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mROSInitException\u001b[0m: Failed to initialize time. Please check logs for additional details"
     ]
    }
   ],
   "source": [
    "rospy.init_node(\"grasp_planner_client\")\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_req = create_grasp_planner_request(\n",
    "    rgb_img=camera_data.rgb_img,\n",
    "    depth_img=camera_data.depth_img,\n",
    "    seg_img=camera_data.seg_img,\n",
    "    pc_points=camera_data.point_cloud_points,\n",
    "    pc_colors=camera_data.point_cloud_colors,\n",
    "    cam_pos=camera_data.cam_pos,\n",
    "    cam_quat=camera_data.cam_quat,\n",
    "    cam_intrinsics=camera_data.cam_intrinsics,\n",
    "    cam_height=CAM_HEIGHT,\n",
    "    cam_width=CAM_WIDTH,\n",
    "    num_of_candidates=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.wait_for_service(GRASP_PLANNER_SERVICE_ID, timeout=30.0)\n",
    "grasp_planner = rospy.ServiceProxy(GRASP_PLANNER_SERVICE_ID, GraspPlanner)\n",
    "\n",
    "reply: GraspPlannerResponse = grasp_planner(grasp_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grasp = sorted(reply.grasp_candidates, key=lambda x: x.score.data)[-1]\n",
    "\n",
    "grasp_pos = best_grasp.pose.pose.position\n",
    "grasp_pos = np.array((grasp_pos.x, grasp_pos.y, grasp_pos.z))\n",
    "\n",
    "grasp_quat = best_grasp.pose.pose.orientation\n",
    "grasp_quat = np.array((grasp_quat.w, grasp_quat.x, grasp_quat.y, grasp_quat.z))\n",
    "\n",
    "grasp_rot = R.from_quat(grasp_quat[[1,2,3,0]]).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_grasping_sequence(\n",
    "    agent = agent,\n",
    "    grasp_pos = grasp_pos,\n",
    "    grasp_quat = grasp_quat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_scene(FACTORY_STRING, scene, agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648fd5414dd759cf455503f1ca8a8d1f6103f81afa3f898375d059feb8b10734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
