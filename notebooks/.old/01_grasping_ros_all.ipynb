{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 28 2022 16:11:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import importlib\n",
    "\n",
    "import rospy\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from alr_sim.core import Scene\n",
    "\n",
    "from grasp_benchmark.utils.ycb_utils import YCBLoader\n",
    "from alr_simulation_tools.scene_utils import execute_grasping_sequence, create_sample_data, reset_scene\n",
    "\n",
    "from grasping_benchmarks_ros.srv import (\n",
    "    GraspPlanner,\n",
    "    GraspPlannerResponse,\n",
    ")\n",
    "\n",
    "from grasp_benchmark.utils.ros_utils import (\n",
    "    create_grasp_planner_request,\n",
    "    calc_point_cloud_from_images\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scene parameters\n",
    "\n",
    "factory_string = \"mj_beta\"\n",
    "object_pos = (0.5, 0.0, 0.2)\n",
    "adhust_object_position = True\n",
    "cam_pos = (0.5, 0.0, 1)\n",
    "cam_quat = [0.7071067811865476, 0.0, 0.0, -0.7071067811865475]\n",
    "cam_height = 480\n",
    "cam_width = 640\n",
    "robot_pos = (0.0, 0.5, 0.2)\n",
    "robot_quat = (0, 1, 0, 0)\n",
    "render_mode = Scene.RenderMode.HUMAN    \n",
    "wait_time = 0.5\n",
    "move_duration = 2\n",
    "\n",
    "# grasp_planner_service_id = \"grconvnet_bench/grconvnet_grasp_planner_service\"\n",
    "grasp_planner_service_id = \"ggcnn_bench/ggcnn_grasp_planner_service\"\n",
    "# grasp_planner_service_id = \"contact_bench/contact_grasp_planner_service\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycb_loader = YCBLoader(\n",
    "    ycb_base_folder=Path.home() / \"Documents\" / \"SF-ObjectDataset\" / \"YCB\", factory_string=\"mj_beta\"\n",
    ")\n",
    "# obj_ids = sorted([p.name for p in ycb_loader.ycb_base_folder.iterdir() if p.is_dir()])\n",
    "obj_ids = [\"011_banana\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node(\"grasp_planner_client\")\n",
    "\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting\n",
      "INFO:root:Creating sample data for 002_master_chef_can\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 002_master_chef_can_orig\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 003_cracker_box\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 004_sugar_box\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 005_tomato_soup_can\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 006_mustard_bottle\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 007_tuna_fish_can\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 008_pudding_box\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 009_gelatin_box\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 010_potted_meat_can\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 011_banana\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 012_strawberry\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 013_apple\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 014_lemon\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 015_peach\n",
      "INFO:root:Sample data created\n",
      "INFO:root:Created request, sending request ...\n",
      "INFO:root:Received grasp candidates\n",
      "INFO:root:Creating sample data for 016_pear\n",
      "/home/moritz/mambaforge/envs/ggcnn/lib/python3.10/site-packages/glfw/__init__.py:912: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCreating sample data for \u001b[39m\u001b[39m{\u001b[39;00mobj_id\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m sim_obj \u001b[39m=\u001b[39m ycb_loader\u001b[39m.\u001b[39mget_ycb_object(pos \u001b[39m=\u001b[39m (\u001b[39m0.5\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.2\u001b[39m), quat \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m), obj_id\u001b[39m=\u001b[39mobj_id, name\u001b[39m=\u001b[39mobj_id)\n\u001b[0;32m----> 8\u001b[0m results, scene, agent \u001b[39m=\u001b[39m create_sample_data(\n\u001b[1;32m      9\u001b[0m     factory_string\u001b[39m=\u001b[39;49mfactory_string,\n\u001b[1;32m     10\u001b[0m     cam_pos\u001b[39m=\u001b[39;49mcam_pos,\n\u001b[1;32m     11\u001b[0m     cam_quat\u001b[39m=\u001b[39;49mcam_quat,\n\u001b[1;32m     12\u001b[0m     cam_height\u001b[39m=\u001b[39;49mcam_height,\n\u001b[1;32m     13\u001b[0m     cam_width\u001b[39m=\u001b[39;49mcam_width,\n\u001b[1;32m     14\u001b[0m     robot_pos\u001b[39m=\u001b[39;49mrobot_pos,\n\u001b[1;32m     15\u001b[0m     robot_quat\u001b[39m=\u001b[39;49mrobot_quat,\n\u001b[1;32m     16\u001b[0m     object_list\u001b[39m=\u001b[39;49m[sim_obj],\n\u001b[1;32m     17\u001b[0m     target_obj_name\u001b[39m=\u001b[39;49mobj_id,\n\u001b[1;32m     18\u001b[0m     render_mode\u001b[39m=\u001b[39;49mrender_mode,\n\u001b[1;32m     19\u001b[0m     wait_time\u001b[39m=\u001b[39;49mwait_time,\n\u001b[1;32m     20\u001b[0m     move_duration\u001b[39m=\u001b[39;49mmove_duration,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mSample data created\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m pc_points, pc_colors \u001b[39m=\u001b[39m calc_point_cloud_from_images(\n\u001b[1;32m     25\u001b[0m     rgb_img\u001b[39m=\u001b[39mresults[\u001b[39m\"\u001b[39m\u001b[39mrgb_img\u001b[39m\u001b[39m\"\u001b[39m], depth_img\u001b[39m=\u001b[39mresults[\u001b[39m\"\u001b[39m\u001b[39mdepth_img\u001b[39m\u001b[39m\"\u001b[39m], cam_intrinsics\u001b[39m=\u001b[39mresults[\u001b[39m\"\u001b[39m\u001b[39mcam_intrinsics\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ALRSimulationTools/alr_simulation_tools/scene_utils.py:83\u001b[0m, in \u001b[0;36mcreate_sample_data\u001b[0;34m(factory_string, cam_pos, cam_quat, cam_height, cam_width, robot_pos, robot_quat, object_list, target_obj_name, render_mode, wait_time, move_duration)\u001b[0m\n\u001b[1;32m     80\u001b[0m scene\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     82\u001b[0m \u001b[39m# go to start position\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m agent\u001b[39m.\u001b[39;49mgotoCartPositionAndQuat(robot_pos, robot_quat, duration\u001b[39m=\u001b[39;49mmove_duration)\n\u001b[1;32m     84\u001b[0m agent\u001b[39m.\u001b[39mwait(wait_time)\n\u001b[1;32m     86\u001b[0m \u001b[39m# get camera data\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SimulationFramework/alr_sim/core/Robots.py:329\u001b[0m, in \u001b[0;36mRobotBase.gotoCartPositionAndQuat\u001b[0;34m(self, desiredPos, desiredQuat, duration, global_coord, block)\u001b[0m\n\u001b[1;32m    324\u001b[0m     desiredQuat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_localize_cart_quat(desiredQuat)\n\u001b[1;32m    326\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgotoCartPosQuatController\u001b[39m.\u001b[39msetDesiredPos(\n\u001b[1;32m    327\u001b[0m     np\u001b[39m.\u001b[39mhstack((desiredPos, desiredQuat))\n\u001b[1;32m    328\u001b[0m )\n\u001b[0;32m--> 329\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgotoCartPosQuatController\u001b[39m.\u001b[39;49mexecuteController(\u001b[39mself\u001b[39;49m, duration, block\u001b[39m=\u001b[39;49mblock)\n",
      "File \u001b[0;32m~/Documents/SimulationFramework/alr_sim/controllers/Controller.py:78\u001b[0m, in \u001b[0;36mControllerBase.executeController\u001b[0;34m(self, robot, maxDuration, block)\u001b[0m\n\u001b[1;32m     75\u001b[0m robot\u001b[39m.\u001b[39mactiveController \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(robot)\n",
      "File \u001b[0;32m~/Documents/SimulationFramework/alr_sim/controllers/Controller.py:60\u001b[0m, in \u001b[0;36mControllerBase.run\u001b[0;34m(self, robot)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Drive the Simulation via the robot.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m    robot (RobotBase): Robot running the controller\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misFinished(robot):\n\u001b[0;32m---> 60\u001b[0m     robot\u001b[39m.\u001b[39;49mnextStep()\n",
      "File \u001b[0;32m~/Documents/SimulationFramework/alr_sim/core/Robots.py:498\u001b[0m, in \u001b[0;36mRobotBase.nextStep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnextStep\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    495\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"legacy method used by the controllers to run the simulation.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m    The function call is now 'redirected' to the scene to support Multibots.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscene\u001b[39m.\u001b[39;49mnext_step()\n",
      "File \u001b[0;32m~/Documents/SimulationFramework/alr_sim/core/Scene.py:138\u001b[0m, in \u001b[0;36mScene.next_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     call_back(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_data()\n\u001b[0;32m--> 138\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[0;32m~/Documents/SimulationFramework/alr_sim/sims/mj_beta/MjScene.py:118\u001b[0m, in \u001b[0;36mMjScene.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mRenderMode\u001b[39m.\u001b[39mHUMAN:\n\u001b[0;32m--> 118\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mviewer\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[0;32m~/Documents/SimulationFramework/alr_sim/sims/mj_beta/mj_utils/mj_renderer.py:606\u001b[0m, in \u001b[0;36mViewer.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_paused:\n\u001b[1;32m    605\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_paused:\n\u001b[0;32m--> 606\u001b[0m         update()\n\u001b[1;32m    607\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_advance_by_one_step:\n\u001b[1;32m    608\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_advance_by_one_step \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting\")\n",
    "for obj_id in obj_ids:\n",
    "\n",
    "    logging.info(f\"Creating sample data for {obj_id}\")\n",
    "\n",
    "    sim_obj = ycb_loader.get_ycb_object(pos = (0.5, 0.0, 0.2), quat = (0,1,0,0), obj_id=obj_id, name=obj_id)\n",
    "\n",
    "    results, scene, agent = create_sample_data(\n",
    "        factory_string=factory_string,\n",
    "        cam_pos=cam_pos,\n",
    "        cam_quat=cam_quat,\n",
    "        cam_height=cam_height,\n",
    "        cam_width=cam_width,\n",
    "        robot_pos=robot_pos,\n",
    "        robot_quat=robot_quat,\n",
    "        object_list=[sim_obj],\n",
    "        target_obj_name=obj_id,\n",
    "        render_mode=render_mode,\n",
    "        wait_time=wait_time,\n",
    "        move_duration=move_duration,\n",
    "    )\n",
    "    logging.info(\"Sample data created\")\n",
    "\n",
    "    pc_points, pc_colors = calc_point_cloud_from_images(\n",
    "        rgb_img=results[\"rgb_img\"], depth_img=results[\"depth_img\"], cam_intrinsics=results[\"cam_intrinsics\"]\n",
    "    )\n",
    "\n",
    "    grasp_req = create_grasp_planner_request(\n",
    "        rgb_img=results[\"rgb_img\"],\n",
    "        depth_img=results[\"depth_img\"],\n",
    "        seg_img=results[\"seg_img\"],\n",
    "        pc_points=pc_points,\n",
    "        pc_colors=pc_colors,\n",
    "        cam_pos=results[\"cam_pos\"],\n",
    "        cam_quat=results[\"cam_quat\"],\n",
    "        cam_intrinsics=results[\"cam_intrinsics\"],\n",
    "        cam_height=cam_height,\n",
    "        cam_width=cam_width,\n",
    "        num_of_candidates=10_000,\n",
    "    )\n",
    "\n",
    "    logging.info(\"Created request, sending request ...\")\n",
    "\n",
    "    rospy.wait_for_service(grasp_planner_service_id, timeout=30.0)\n",
    "    grasp_planner = rospy.ServiceProxy(grasp_planner_service_id, GraspPlanner)\n",
    "\n",
    "    reply: GraspPlannerResponse = grasp_planner(grasp_req)\n",
    "    logging.info(\"Received grasp candidates\")\n",
    "\n",
    "    # best_grasp = sorted(reply.grasp_candidates, key=lambda x: x.score.data)[-1]\n",
    "    # grasp_pos = best_grasp.pose.pose.position\n",
    "    # grasp_pos = (grasp_pos.x, grasp_pos.y, grasp_pos.z)\n",
    "    # grasp_quat = best_grasp.pose.pose.orientation\n",
    "    # grasp_quat = (grasp_quat.w, grasp_quat.x, grasp_quat.y, grasp_quat.z)\n",
    "\n",
    "    # execute_grasping_sequence(\n",
    "    #     agent = agent,\n",
    "    #     grasp_pos = grasp_pos,\n",
    "    #     grasp_quat = grasp_quat\n",
    "    # )\n",
    "\n",
    "    reset_scene(factory_string, scene, agent)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648fd5414dd759cf455503f1ca8a8d1f6103f81afa3f898375d059feb8b10734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
